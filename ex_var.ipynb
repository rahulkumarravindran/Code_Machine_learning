{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 354)\n",
      "0.7383919489335855\n"
     ]
    }
   ],
   "source": [
    "#read the data from the original CSV \r\n",
    "data=pd.read_csv(r\"D:\\Windsor\\Fourth semester\\Applied Machine learning\\Project\\Datasets\\Datasets\\D1.csv\",header=None)\r\n",
    "\r\n",
    "#List of dimension reduced datasets\r\n",
    "DR_datasets={'Conformal Eigenmaps':r\"D:\\Windsor\\Fourth semester\\Applied Machine learning\\Project\\Code_Machine_learning\\DimensionReducedDataSet\\D1_CE.csv\",'Maximum Variance Unfolding':r\"D:\\Windsor\\Fourth semester\\Applied Machine learning\\Project\\Code_Machine_learning\\DimensionReducedDataSet\\D1_MVU.csv\", \"Landmark MVU\": r\"D:\\Windsor\\Fourth semester\\Applied Machine learning\\Project\\Code_Machine_learning\\DimensionReducedDataSet\\D1_LMVU.csv\"}\r\n",
    "\r\n",
    "#Separating the data and the labels\r\n",
    "x=data.iloc[:,:-1]\r\n",
    "y=data.iloc[:,-1:]\r\n",
    "\r\n",
    "#Scale the data\r\n",
    "#scaler=StandardScaler()\r\n",
    "#x=scaler.fit_transform(x)\r\n",
    "\r\n",
    "print(x.shape)\r\n",
    "varM=x.var().sum()\r\n",
    "\r\n",
    "print(varM)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ev of Conformal Eigenmaps: [6.620306760947506e-05, 1.0130668231797236e-05, 1.0990499981545971e-08, 7.704126500734031e-05, 3.348853709727518e-07, 1.7449749400090114e-09, 1.0202092974114171e-05, 1.022140068516782e-05, 1.0210302022227554e-05] and overall ev is 0.00018435641737601647\n",
      "ev of Maximum Variance Unfolding: [0.002211940252181548, 0.00033413343798390914, 6.760782983753336e-10, 9.244189709515607e-06, 1.3722384115180526e-06, 5.164381580642877e-07, 0.008761180600877745, 0.000805399645056288, 0.00016660808642142574] and overall ev is 0.012290395564878313\n",
      "ev of Landmark MVU: [1.3659252420331505e-10, 0.17825258195583193, 0.006583208147311081, 0.0001253936386942132, 0.004160054935519003, 4.7825633913243495e-05] and overall ev is 0.189169064447862\n"
     ]
    }
   ],
   "source": [
    "for i in DR_datasets:\r\n",
    "    #Reading the dimension Reduced dataset\r\n",
    "    #The dataset is already preprocessed, So there is no need to fill missing values or Scale\r\n",
    "    data_dr=pd.read_csv(DR_datasets[i],header=None)\r\n",
    "\r\n",
    "    #data_dr=data_dr.loc[(data_dr!=0).any(axis=1),:]\r\n",
    "\r\n",
    "    #find the shape of Dimesnion Reduced dataset\r\n",
    "    (m_dr,n_dr)=data_dr.shape\r\n",
    "\r\n",
    "    #print(n_dr)\r\n",
    "\r\n",
    "    #Separating the data and the labels\r\n",
    "    x_dr=data_dr.iloc[:,:-1]\r\n",
    "    y_dr=data_dr.iloc[:,-1:]\r\n",
    "\r\n",
    "    #Scale the data\r\n",
    "    #scaler=StandardScaler()\r\n",
    "    #x_dr=scaler.fit_transform(x_dr)\r\n",
    "\r\n",
    "    varD=x_dr.var(axis=0)\r\n",
    "    #print(varD)\r\n",
    "\r\n",
    "    ev=varD/varM\r\n",
    "\r\n",
    "    for j in range(len(ev)):\r\n",
    "        if ev[j]>1:\r\n",
    "            ev[j]=1/ev[j]\r\n",
    "\r\n",
    "    print(\"ev of {}: {} and overall ev is {}\".format(i,list(ev),sum(ev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}